{
  "llama3.2": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "llama3.2 - Meta - text model family (Meta). Gute Allround-Leistung; häufig für tool-workflows genutzt."
  },
  "llama3.2-vision": {
    "vision": true,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 128,
    "description": "llama3.2-vision - Meta - multimodales Llama-3.2 Modell mit Bildverständnis."
  },
  "llama3.1": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "llama3.1 - Meta - größere Llama-Familie mit sehr guten allgemeinen Fähigkeiten."
  },
  "llama2": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "llama2 - Meta - klassische Llama-Foundation-Modelle (7B–70B)."
  },
  "llama2-chat": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "llama2-chat - Meta - Llama 2 Chat-tuned Variante für konversationelle Anwendungen."
  },
  "code-llama": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "code-llama - Meta - für Programmier- und Code-Aufgaben optimiert."
  },
  "starcoder": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "starcoder - BigCode - Open-source-Code-Model, gut für Code-Vervollständigung und Analyse."
  },
  "starcoder2": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "starcoder2 - BigCode - Weiterentwicklung von StarCoder mit verbessertem Codeverständnis."
  },
  "mistral": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 32,
    "description": "mistral - Mistral AI - effizientes, leistungsfähiges Textmodell; oft in tool-Setups verwendet."
  },
  "mistral-small": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "mistral-small - Mistral AI - kleinere, schnelle Mistral-Variante."
  },
  "mistral-nemo": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 1000,
    "description": "mistral-nemo - Mistral AI - größere Mistral-Variante mit erweitertem Kontext/Leistung."
  },
  "phi3-mini": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "phi3-mini - Microsoft - leichtgewichtiges Microsoft-Modell (nützlich für ressourcenarme Setups)."
  },
  "phi3-medium": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "phi3-medium - Microsoft - ausgewogener Kompromiss zwischen Leistung und Ressourceneinsatz."
  },
  "gemma2": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "gemma2 - Google - Google-Modelle, mehrere Größen; gute Basisleistung."
  },
  "gemma2-vision": {
    "vision": true,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "gemma2-vision - Google - Google-Modelle der Gemma-Familie mit Multimodal-/Bildunterstützung."
  },
  "gemma3": {
    "vision": true,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 128,
    "description": "gemma3 - Google - multimodale Familie (Text+Bild) von Google, große Kontextfenster verfügbar."
  },
  "qwen2": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "qwen2 - Alibaba - Alibaba-Modellfamilie, gut in mehreren Größen und für Tool-Workflows geeignet."
  },
  "qwen3-vl": {
    "vision": true,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 32,
    "description": "qwen3-vl - Alibaba - leistungsfähiges Vision-Language Modell (multimodal, Tool-freundlich)."
  },
  "llava": {
    "vision": true,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "llava - LLaVA - Vision+Language Assistant; stark bei Bild-Captioning und visuellen QA."
  },
  "wizardlm": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "wizardlm - WizardLM - instruction-tuned Modell, oft für Tool-Calling und Assistenz verwendet."
  },
  "wizardlm2": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "wizardlm2 - WizardLM - neuere Instruction-Variante mit verbessertem Reasoning."
  },
  "dolly": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "dolly - Databricks - offene Instruction-tuned Modelle, für einfache Assistenzaufgaben nützlich."
  },
  "dolly-v2": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "dolly-v2 - Databricks - verbesserte Instruction-Version der Dolly-Familie."
  },
  "deepseek-coder": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "deepseek-coder - DeepSeek - spezialisiertes Modell für Programmieraufgaben."
  },
  "command-r": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "command-r - Cohere - konversations-/Anwendungsoptimiertes Modell mit Fokus auf lange Kontexte."
  },
  "granite3.2-vision": {
    "vision": true,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "granite3.2-vision - IBM - kompaktes Vision-Language Modell, gut für Dokument-Parsing."
  },
  "smollm2": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "smollm2 - SmolLM - sehr kleine, effiziente Modelle (135M–1.7B) für ressourcenbeschränkte Systeme."
  },
  "smollm": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "smollm - SmolLM - Reihe von kompakten Modellen für einfache Aufgaben."
  },
  "qwen-chat": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "qwen-chat - Alibaba - chat-optimierte Version der Qwen-Reihe."
  },
  "codellama-instruct": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "codellama-instruct - Meta - instruction-tuned Varianten von CodeLlama."
  },
  "starcoder-instruct": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "starcoder-instruct - BigCode - anweisungsoptimierte Code-Variante."
  },
  "deepseek-r1": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": true,
    "context_kB": 120,
    "description": "deepseek-r1 - DeepSeek - reasoning-orientiertes Modell, gut für anspruchsvolle NLP-Aufgaben."
  },
  "gemma2-chat": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "gemma2-chat - Google - chat-tuned Variante der Gemma2 Familie."
  },
  "aya": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "aya - Cohere - ein mehrsprachiges Modell, gut für Übersetzung und Multilingual-Tasks."
  },
  "command-r-xl": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "command-r-xl - Cohere - XL-Version für lange Kontexte und komplexe Dialoge."
  },
  "wizard-vicuna": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "wizard-vicuna - WizardLM - instruction-tuned Varianten, häufig für Assistenz/Tool-Workflows."
  },
  "dolphin": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "dolphin - Unknown - leistungsstarke Familie mit starker Leistung in offenen Benchmarks."
  },
  "yi-vision": {
    "vision": true,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "yi-vision - 01.AI - multimodales Modell mit Bildverarbeitungsfähigkeiten."
  },
  "tinyllama": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "tinyllama - Meta - sehr kleine Llama-Ableitungen für Embedded/Edge-Usecases."
  },
  "phoenix": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "phoenix - Together AI - Modellfamilie mit Fokus auf Retrieval/Tool-Integration."
  },
  "phoenix-vl": {
    "vision": true,
    "tools": true,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "phoenix-vl - Together AI - Vision-Language Ableitung von Phoenix mit Tool-Support."
  },
  "starcoder-mini": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "starcoder-mini - BigCode - kleinere, schnelle Code-Modelle."
  },
  "codellama-text-small": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "codellama-text-small - Meta - kleinere Textversion für Low-Resource-Usecases."
  },
  "mpt": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "mpt - MosaicML - MosaicML Modelle, beliebt für Fine-Tuning und Research."
  },
  "mpt-vision": {
    "vision": true,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "mpt-vision - MosaicML - multimodale MPT Variante."
  },
  "gemma-3b": {
    "vision": true,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 0,
    "description": "gemma-3b - Google - Gemma Familie kleine Größen (text+vision je nach Tag)."
  },
  "qwen3": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": true,
    "context_kB": 0,
    "description": "qwen3 - Alibaba - Qwen 3 – leistungsstarkes LLM mit Tool-Unterstützung und Mehrsprachen-Fähigkeit."
  },
  "gpt-oss": {
    "vision": false,
    "tools": true,
    "embedding": false,
    "thinking": true,
    "context_kB": 120,
    "description": "gpt-oss - Open AI - GPT-OSS – offenes GPT-Modell mit Tool-Unterstützung für vielfältige Aufgaben."
  },
  "codellama": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 10,
    "description": "codellama - Meta - GPT-OSS – ein Modell um Code zu generieren."
  },
  "deepscaler": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": true,
    "context_kB": 120,
    "description": "DeepScaleR - Deepseek - sehr kleines effizientes Modell, welches eine hohe Pass Genauigkeit erreicht."
  },
  "phi4": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 16,
    "description": "phi4 - Microsoft - Das Modell ist darauf ausgelegt, die Forschung an Sprachmodellen zu beschleunigen."
  },
  "gurubot/alpha-orionis-uncensored": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 32,
    "description": "alpha-orionis-uncensored - WizardLM - Ein Ableger von WizardLM, fine tuned and unzensed."
  },
  "openthinker": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 32,
    "description": "openthinker - Open Thoughts - eine Destillation von DeepSeek-R1."
  },
  "deepseek-coder-v2": {
    "vision": false,
    "tools": false,
    "embedding": false,
    "thinking": false,
    "context_kB": 160,
    "description": "deepseek-coder-v2 - Deepseek - Ein Open-Source-Mixture-of-Experts-Codesprachenmodell."
  }

}